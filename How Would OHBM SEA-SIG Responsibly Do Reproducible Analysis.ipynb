{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415e7619",
   "metadata": {},
   "source": [
    "# How Would OHBM SEA-SIG Responsibly Do Reproducible Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe368b",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "We have one MRI dataset organized following the [Brain Imaging Data Structure (BIDS)](https://bids-specification.readthedocs.io/en/stable/) community standard; we want to run the container of one BIDS App (`mriqc` for instance here); and we’d like not only to \"manage\" the process and output in a reproducible way but also to track the carbon footprint of the run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05eb33",
   "metadata": {},
   "source": [
    "## OHBM SEA-SIG Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc71d1ff",
   "metadata": {},
   "source": [
    "### In theory\n",
    "\n",
    "#### Reproducible analysis of a dataset\n",
    "\n",
    "To achieve full reproducibility of an analysis of a BIDS dataset with a container, best practices suggest that the dataset and the container should be under content management, and you should run your processing in a way that manages the output. At first, this can sound quite complicated especially if you are not familiar with version control system such as `Git`, but [ReproNim: A Center for Reproducible Neuroimaging Computation](https://www.repronim.org) and many other collaborators have contributed during the past 5 years with a great series of tools, principles, and tutorials that have made this task very accessible, that we will adopt. They are the following: \n",
    "\n",
    "*   [`Datalad`](https://www.datalad.org/): open source distributed data management system built on top of git and git-annex.\n",
    "\n",
    "    > \"DataLad is a free and open source distributed data management system that keeps track of your data, creates structure, ensures reproducibility, supports collaboration, and integrates with widely used data infrastructure.\" - [\"https://www.datalad.org/\"](https://www.datalad.org/)\n",
    "\n",
    "*   [`datalad-container`](https://pypi.org/project/datalad-container/): DataLad extension for containerized environments.\n",
    "\n",
    "    > \"This extension equips DataLad’s run/rerun functionality with the ability to transparently execute commands in containerized computational environments. On re-run, DataLad will automatically obtain any required container at the correct version prior execution.\" - [\"http://docs.datalad.org/projects/container\"](http://docs.datalad.org/projects/container)\n",
    "\n",
    "*   `YODA` ([YODA’s organigram on data analysis](https://github.com/myyoda)) principles.\n",
    "    \n",
    "    > \"The principles outlined in YODA set simple rules for directory names and structures, best-practices for version-controlling dataset elements and analyses, facilitate usage of tools to improve the reproducibility and accountability of data analysis projects, and make collaboration easier.\" - [\"Datalad Handbook Chapter 6.2 - YODA: Best practices for data analyses in a dataset\"][2]\n",
    "    \n",
    "*   [`ReproNim/containers`](): Datalad dataset with a collection of 40 popular computational tools provided within ready to use containerized environments.\n",
    "    Designed to be easily included as a subdataset within larger study (super)datasets to facilitate rapid and\n",
    "    reproducible computation, while adhering to [YODA principles] and retaining clear and unambiguous\n",
    "    association between data, code, and computing environments using DataLad and its `datalad-container`extension.\n",
    "\n",
    "So practically, this means that we should adhere to the YODA principles and put the project dataset under Datalad control, install the Datalad dataset of the input BIDS dataset and the `ReproNim/containers` as subdatasets, and run the container on the data using [`datalad run-containers`](http://docs.datalad.org/projects/container/en/stable/generated/man/datalad-containers-run.html#) which will record what you did to the data, and with what.\n",
    "\n",
    "Thanks to git-annex, when a Datalad dataset is installed, the copy does not contain the contents of all annexed files by default, but display only file names. It is only when a file is needed for analysis that its content can be retrieved, which makes it very efficient in dealing with very large datasets; we should expect a positive impact on the carbon emissions indured by this process. Adopting the ecosystem of ReproNim tools can thus not only provides us with a complete and easy way to achieve full reproducibility of an analysis of a BIDS dataset, but also with a more responsible way to handle, reuse, and share our data and analysis.\n",
    "\n",
    "##### Want to know more about Datalad  and the YODA principles?\n",
    "\n",
    "Check the [Datalad handbook](https://handbook.datalad.org) (YODA principles available in [\"Chapter 6.2 - YODA: Best practices for data analyses in a dataset\"][2]) as well as the tutorials [\"ReproIn/DataLad: A complete portable and reproducible fMRI study from scratch\"](http://www.repronim.org/sfn2018-training/04-02-reproin/) and [\"How Would ReproNim Do Local Container Analysis\"][1].\n",
    "\n",
    "#### Tracking of CO2 emissions of code execution\n",
    "\n",
    "To track the carbon footprint of your run, there exists a few solution in Python for the moment such as [carbontracker](https://github.com/lfwa/carbontracker), [experiment-impact-tracker](https://github.com/Breakend/experiment-impact-tracker), and [codecarbon](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwig6J-1o7b0AhWziP0HHczsDP8QFnoECAcQAQ&url=https%3A%2F%2Fcodecarbon.io%2F&usg=AOvVaw0H9DY5tnp8PbQ9i-3U32ES). Here we will use `codecarbon`, but all solutions (1) works on systems with Intel chips (that supports the RAPL or powergadget interfaces) and NVIDIA GPUs and necessitates the embedding of only a few lines in the code, and (3) estimates the amount of carbon dioxide (CO2) produced by its execution. Going from one tool to another should be achieved with a relatively little effort.\n",
    "\n",
    "[1]: <https://how-would.repronim.org/en/latest/vol01/localcontainer.html> \"How Would ReproNim Do Local Container Analysis\"\n",
    "[2]: <https://handbook.datalad.org/en/latest/basics/101-127-yoda.html> \"Datalad Handbook Chapter 6.2 - YODA: Best practices for data analyses in a dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a63e0b",
   "metadata": {},
   "source": [
    "### In practice\n",
    "\n",
    "To show this in practice, we build on the [Typical workflow example](https://github.com/ReproNim/containers#a-typical-workflow) of the README of `ReproNim/containers` (which shows how to adhere to the YODA principles and use datalad, datalad-containers, and `ReproNim/containers` to run [`mriqc 0.16.0`](https://mriqc.readthedocs.io) on a [demo BIDS dataset](https://github.com/ReproNim/ds000003-demo) in a fully reproducible manner from the terminal), that is translated into Python using `datalad.api` (the Python API of Datalad) and extended with the embedding of the following codecarbon code responsible for the estimation of the carbon footprint indurred by the execution of `mriqc`:\n",
    "```python\n",
    "# Create and start the carbon footprint tracker\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "[...]\n",
    "\n",
    "# Stop the carbon footprint tracker and get the estimated CO2 emissions\n",
    "emissions: float = tracker.stop()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2e0a3",
   "metadata": {},
   "source": [
    "#### 1. Import the different packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8fb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Make datalad.api happy in the notebokk\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Import Datalad Python API\n",
    "import datalad.api as dl\n",
    "\n",
    "# Import the carbon tracker of codecarbon\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d653c9e",
   "metadata": {},
   "source": [
    "#### 2. Create the project dataset that will contain `mriqc` output \n",
    "\n",
    "The code below creates a new Datalad dataset in `ds000003-qc` directory and tells Datalad to use Git to manage text files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74fbf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectds = 'ds000003-qc'\n",
    "projectds_dir = (Path(os.getcwd()) / projectds)\n",
    "ds = dl.create(path=projectds_dir, cfg_proc='text2git')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564af031",
   "metadata": {},
   "source": [
    "Change the current working directory to the project dataset directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(ds.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfdaea8",
   "metadata": {},
   "source": [
    "#### 3. Install the [ReproNim/containers dataset](https://github.com/ReproNim/containers)\n",
    "\n",
    "The code below installs the `ReproNim/containers` as a subdataset under the ``containers`` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_containers = dl.install(\n",
    "    dataset=ds,\n",
    "    source='///repronim/containers',\n",
    "    path='containers'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b0605",
   "metadata": {},
   "source": [
    "`ReproNim/containers` currently references a collection of 40 popular computational tools provided within ready to use containerized environments, which can be shown with `ds.containers_list(recursive=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb6665",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds.containers_list(recursive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630cf4fc",
   "metadata": {},
   "source": [
    "#### 4. Freeze `mriqc` version to ``0.16.0``\n",
    "\n",
    "`ReproNim/containers` provides a collection of utility scripts in `scripts` directory. The code below runs `freeze_versions`  with `datalad run` to ensure `mriqc 0.16.0` will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938278b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = ds.run(\n",
    "    message=\"Downgrade/Freeze mriqc container version\",\n",
    "    cmd='containers/scripts/freeze_versions \"bids-mriqc=0.16.0\"'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a185a665",
   "metadata": {},
   "source": [
    " All modifications made by the execution of the script are thus recorded with a brief and comprehensive `message`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0350881b",
   "metadata": {},
   "source": [
    "#### 5. Install input dataset\n",
    "\n",
    "The code below installs the dataset redistributed by ReproNim for their [Typical workflow example](https://github.com/ReproNim/containers#a-typical-workflow) of the `ReproNim/containers`, a sample of the [OpenNeuro ds000003 dataset](https://openneuro.org/datasets/ds000003) with two participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aed0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sourcedata = dl.install(\n",
    "    dataset=ds,\n",
    "    source='https://github.com/ReproNim/ds000003-demo',\n",
    "    path='sourcedata'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd882a7",
   "metadata": {},
   "source": [
    "#### 6. Run `mriqc` with `datalad run-containers` with carbon footprint tracking\n",
    "\n",
    "To track carbon footprint during the execution of `mriqc` with `datalad run-containers`, we just need to surround the invocation of the `containers_run` (the Datalad Python API equivant of `datalad run-containers`) with a few lines of `codecarbon` code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a code/ directory in the dataset\n",
    "# where codecarbon will save CO2 emissions\n",
    "# in a CSV file called \"emissions.csv\"\n",
    "code_dir = str(Path(ds.path) / \"code\")\n",
    "os.makedirs(code_dir, exist_ok = True)\n",
    "\n",
    "# Create and start the carbon footprint tracker\n",
    "tracker = EmissionsTracker(\n",
    "    project_name=f\"mriqc-0.16.0\",\n",
    "    output_dir=code_dir,\n",
    "    measure_power_secs=15,\n",
    ")\n",
    "tracker.start()\n",
    "\n",
    "# Run `mriqc` with `datalad run-containers`\n",
    "mriqc_run_results = ds.containers_run(\n",
    "    cmd='{inputs} {outputs} participant group -w workdir',\n",
    "    inputs=[\"sourcedata\"],\n",
    "    outputs=[\"derivatives\"],\n",
    "    container_name=\"containers/bids-mriqc\"\n",
    ")\n",
    "\n",
    "# Stop the carbon footprint tracker and get the estimated CO2 emissions\n",
    "emissions: float = tracker.stop()\n",
    "print(f\"CARBON FOOTPRINT:\\n\\t* Estimated Co2 emissions = {emissions} kg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bbbc97",
   "metadata": {},
   "source": [
    "where we tells `datalad run-containers` to run the container `\"containers/bids-mriqc\"` with the command `cmd='{inputs} {outputs} participant group -w workdir'`. `{inputs}` and `{outputs}` are placeholders that are filled with the value of `inputs` (here `\"sourcedata\"`) and `outputs` (here `\"derivatives\"`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f319e5",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "You now know how to analyze the demo BIDS dataset with a container of the collection of `ReproNim/containers`.\n",
    "From this basic knowledge you should be able with little effort to customize this approach\n",
    "to use any of the 40 tools provided by `ReproNim/containers` (such as `fmriprep`, `qsiprep`,...) on the collection of datasets already available to the community on OpenNeuro or on your own BIDS dataset that is under Datalad control, and track your carbon emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a5715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
